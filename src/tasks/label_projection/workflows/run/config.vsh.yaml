functionality:
  name: "run_benchmark"
  namespace: "label_projection/workflows"
  argument_groups:
    - name: Inputs
      arguments:
        - name: "--id"
          type: "string"
          description: "The ID of the normalized dataset"
          required: true
        - name: "--input_train"
          # __merge__: ../../api/file_train.yaml
          type: file
          direction: input
          required: true
        - name: "--input_test"
          # __merge__: ../../api/file_test.yaml
          type: file
          direction: input
          required: true
        - name: "--input_solution"
          # __merge__: ../../api/file_solution.yaml
          type: file
          direction: input
          required: true
    - name: Outputs
      arguments:
        - name: "--output"
          direction: "output"
          type: file
          example: output.tsv
  resources:
    - type: nextflow_script
      path: main.nf
      entrypoint: run_wf
  dependencies:
    - name: common/check_dataset_schema
    - name: common/extract_scores
    - name: label_projection/control_methods/true_labels
    - name: label_projection/control_methods/majority_vote
    - name: label_projection/control_methods/random_labels
    - name: label_projection/methods/knn
    - name: label_projection/methods/logistic_regression
    - name: label_projection/methods/mlp
    - name: label_projection/methods/scanvi
    - name: label_projection/methods/scanvi_scarches
    - name: label_projection/methods/xgboost
    - name: label_projection/metrics/accuracy
    - name: label_projection/metrics/f1
  # test_resources:
  #   - type: nextflow_script
  #     path: main.nf
  #     entrypoint: test_wf
platforms:
  - type: nextflow