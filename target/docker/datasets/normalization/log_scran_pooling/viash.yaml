functionality:
  name: "log_scran_pooling"
  namespace: "datasets/normalization"
  version: "main_build"
  authors: []
  inputs: []
  outputs: []
  arguments:
  - type: "file"
    name: "--input"
    alternatives: []
    description: "An unprocessed dataset as output by a dataset loader."
    info:
      label: "Raw dataset"
      slots:
        layers:
        - type: "integer"
          name: "counts"
          description: "Raw counts"
          required: true
        obs:
        - type: "string"
          name: "celltype"
          description: "Cell type information"
          required: false
        - type: "string"
          name: "batch"
          description: "Batch information"
          required: false
        - type: "string"
          name: "tissue"
          description: "Tissue information"
          required: false
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
    example:
    - "raw_dataset.h5ad"
    default: []
    must_exist: false
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  - type: "file"
    name: "--output"
    alternatives: []
    description: "A normalized dataset"
    info:
      label: "Normalized dataset"
      slots:
        layers:
        - type: "integer"
          name: "counts"
          description: "Raw counts"
          required: true
        - type: "double"
          name: "normalized"
          description: "Normalised expression values"
        obs:
        - type: "string"
          name: "celltype"
          description: "Cell type information"
          required: false
        - type: "string"
          name: "batch"
          description: "Batch information"
          required: false
        - type: "string"
          name: "tissue"
          description: "Tissue information"
          required: false
        - type: "double"
          name: "size_factors"
          description: "The size factors created by the normalisation method, if any."
          required: false
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
        - type: "string"
          name: "normalization_id"
          description: "Which normalization was used"
          required: true
    example:
    - "dataset.h5ad"
    default: []
    must_exist: false
    required: false
    direction: "output"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  - type: "string"
    name: "--layer_output"
    alternatives: []
    description: "The name of the layer in which to store the normalized data."
    example: []
    default:
    - "normalized"
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  - type: "string"
    name: "--obs_size_factors"
    alternatives: []
    description: "In which .obs slot to store the size factors (if any)."
    example: []
    default:
    - "size_factors"
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  argument_groups: []
  resources:
  - type: "r_script"
    path: "script.R"
    is_executable: true
  description: "Normalize data using scran pooling"
  test_resources:
  - type: "python_script"
    text: "import anndata as ad\nimport subprocess\nfrom os import path\n\ninput_path\
      \ = meta[\"resources_dir\"] + \"/pancreas/dataset.h5ad\"\noutput_path = \"output.h5ad\"\
      \noutput_layer = \"norm_layer\"\n\ncmd = [\n  meta['executable'],\n  \"--input\"\
      , input_path,\n  \"--output\", output_path,\n  \"--layer_output\", output_layer\n\
      ]\n\nprint(\">> Running script as test\")\nout = subprocess.check_output(cmd).decode(\"\
      utf-8\")\n\nprint(\">> Checking whether output file exists\")\nassert path.exists(output_path)\n\
      \nprint(\">> Reading h5ad files\")\ninput = ad.read_h5ad(input_path)\noutput\
      \ = ad.read_h5ad(output_path)\nprint(\"input:\", input)\nprint(\"output:\",\
      \ output)\n\nprint(\">> Checking whether output data structures were added\"\
      )\nassert output_layer in output.layers\n\nprint(\"Checking whether data from\
      \ input was copied properly to output\")\nassert input.n_obs == output.n_obs\n\
      assert input.uns[\"dataset_id\"] == output.uns[\"dataset_id\"]\n\nprint(\"All\
      \ checks succeeded!\")\n"
    dest: "generic_test.py"
    is_executable: true
  - type: "file"
    path: "../../../../resources_test/common/pancreas"
  status: "enabled"
  requirements:
    commands: []
  set_wd_to_resources_dir: false
platforms: []
info:
  config: "src/datasets/normalization/log_scran_pooling/config.vsh.yaml"
  platform: "docker"
  output: "target/docker/datasets/normalization/log_scran_pooling"
  executable: "target/docker/datasets/normalization/log_scran_pooling/log_scran_pooling"
  viash_version: "0.6.4"
  git_commit: "d3b8232e9b7a29b3eb8e13a5865a209c8badeea1"
  git_remote: "https://github.com/openproblems-bio/openproblems-v2"
